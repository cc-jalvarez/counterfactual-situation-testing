{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working script for cfST\n",
    "\n",
    "Use to greate the functions from_groups(), test_disc()... part of run_cfST()\n",
    "\n",
    "From Salvatore's paper: \"it boils down to the Manhattan distance of z-scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory - note: all code runs from the src folder\n",
    "wrk_dir = os.getcwd()\n",
    "# data path\n",
    "data_path = wrk_dir + '\\\\' + 'data' + '\\\\'\n",
    "# results path\n",
    "resu_path = wrk_dir + '\\\\' + 'results\\\\counterfactuals' + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4993, 6)\n",
      "(4993, 6)\n"
     ]
    }
   ],
   "source": [
    "df    = pd.read_csv(data_path + 'Karimi2020_v2.csv', sep='|', )\n",
    "print(df.shape)\n",
    "cf_df = pd.read_csv(resu_path + 'cf_Karimi2020_v2.csv', sep='|', )\n",
    "print(cf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df[df['Gender']==1].shape[0]/df.shape[0]*100, 3) # perc. of women in df\n",
    "#df[df['Gender']==0].shape[0]/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df['LoanApproval'])\n",
    "# plt.hist(cf_df['LoanApproval']) # number of denied loans drops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[(df['Gender']==1) & (df['LoanApproval']==1)].shape[0]/df.shape[0]*100)\n",
    "print('--- vs ---')\n",
    "print(cf_df[(cf_df['Gender']==1) & (cf_df['LoanApproval']==1)].shape[0]/cf_df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_trgt = 'LoanApproval'\n",
    "feat_trgt_vals = {'pos': 1, 'neg': -1} # 'pos' for the desired label, 'neg' for the undesired label\n",
    "# feat_rlvt = ['AnnualSalary']\n",
    "feat_rlvt = ['AnnualSalary', 'AccountBalance']\n",
    "feat_prot = 'Gender'\n",
    "feat_prot_vals = {'non_protected': 0, 'protected': 1} # indicate labels for non-protected and protected groups\n",
    "\n",
    "# future params!\n",
    "# protected_group = {'Gender': 1} \n",
    "n = 10 # determine by power analysis? (future extension)\n",
    "d = 'manhattan' # ‘manhattan’ - see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html\n",
    "\n",
    "weights = None\n",
    "# weights = {'AnnualSalary': 5, 'AccountBalance': 1}\n",
    "standardize = True\n",
    "\n",
    "\n",
    "# delete once functions have been tested\n",
    "feat_list = [feat_trgt] + feat_rlvt + [feat_prot]\n",
    "# feat_list = feat_trgt + feat_rlvt\n",
    "# feat_list.append(feat_prot)\n",
    "feat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under counterfactual situation testing, for the protected group we need to create two groups: a *control group* (CG) centered on the factuals and a *test group* (TG) centered on the counterfactuals. In practice, this means that we take individual women and compare them to other similar women using some distance $d_1$ to construct CG, while we take their corresponding counterfactuals and compare them to similar men using some distance $d_2$. We start off with $d_1=d_2$. We create the groups using a KNN algorithm.\n",
    "\n",
    "Under this approach, rather than centering both CG and TG on the same (factual) instance, we construct the hypothetical group (*what would have happened had the female individual been male?*) by allowing for all variables to adjust due to the change in $A$. This is our implementation of what Kohler defined as *fairness given the difference* and what she arguess through her Eddie Murphy paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: individuals have the same index across df and cf_df\n",
    "protected_indices     = df[df[feat_prot]==feat_prot_vals['protected']].index.to_list()\n",
    "non_protected_indices = df[df[feat_prot]==feat_prot_vals['non_protected']].index.to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Setup the respectice search spaces for control (ctr) and test (tst) groups\n",
    "# use factual df for ctr\n",
    "search_ctr_group = df[feat_rlvt].copy()\n",
    "print(search_ctr_group.shape)\n",
    "# use counterfactual df for tst\n",
    "search_tst_group = cf_df[feat_rlvt].copy()\n",
    "print(search_tst_group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we pre-process, the search_spaces must include the centers | TODO: do we normalize after ot before partitioning by A? decide in previous cell\n",
    "if standardize:\n",
    "    print('standardizing')\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    \n",
    "    search_ctr_group_scaled = scaler.fit_transform(search_ctr_group)\n",
    "    search_ctr_group_scaled = pd.DataFrame(search_ctr_group_scaled, index=search_ctr_group.index, columns=search_ctr_group.columns)\n",
    "    search_ctr_group = search_ctr_group_scaled\n",
    "    del search_ctr_group_scaled\n",
    "    \n",
    "    search_tst_group_scaled = scaler.fit_transform(search_tst_group)\n",
    "    search_tst_group_scaled = pd.DataFrame(search_tst_group_scaled, index=search_tst_group.index, columns=search_tst_group.columns)\n",
    "    search_tst_group = search_tst_group_scaled\n",
    "    del search_tst_group_scaled\n",
    "\n",
    "if weights:\n",
    "    print('weighting')\n",
    "    \n",
    "    if len(weights) != len(feat_rlvt):\n",
    "        sys.exit('provide a weight for each relevant feature')\n",
    "    \n",
    "    for feat_weight in weights:\n",
    "        print(feat_weight)\n",
    "        search_ctr_group[feat_weight] = weights[feat_weight] * search_ctr_group[feat_weight]\n",
    "        search_tst_group[feat_weight] = weights[feat_weight] * search_tst_group[feat_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_ctr = search_ctr_group.iloc[protected_indices].copy() # search_ctr_group will always include the ctr center\n",
    "\n",
    "search_ctr_group = search_ctr_group.iloc[protected_indices].copy()\n",
    "search_ctr_group.reset_index(inplace=True, )\n",
    "search_ctr_group.rename(columns={'index': 'org_index'}, inplace=True)\n",
    "\n",
    "print(search_ctr_group.shape)\n",
    "search_ctr_group.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_ctr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_tst = search_tst_group.iloc[protected_indices].copy()\n",
    "\n",
    "# define the search space within the loop (unfortunately...)\n",
    "# search_tst_group = search_tst_group.iloc[non_protected_indices].copy()\n",
    "# search_tst_group.reset_index(inplace=True, )\n",
    "# search_tst_group.rename(columns={'index': 'org_index'}, inplace=True)\n",
    "\n",
    "# print(search_tst_group.shape)\n",
    "# search_tst_group.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_tst.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the main function here...\n",
    "\n",
    "# store neighboors here\n",
    "dict_df_neighbors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) For eahc ind(ividual) set the centers\n",
    "\n",
    "ind = 0 # start loop: for ind in protected_indices:\n",
    "\n",
    "# for storing the neighboors \n",
    "temp_dict_df_neighbors = {}\n",
    "\n",
    "# get ctr center from df of factual centers\n",
    "ind_center_ctr = centers_ctr.loc[ind, ] #[ind, feat_rlvt]\n",
    "\n",
    "print(ind_center_ctr)\n",
    "\n",
    "# get tst center from df of counterfactual centers\n",
    "ind_center_tst = centers_tst.loc[ind, ] #[ind, feat_rlvt]\n",
    "\n",
    "print(ind_center_tst)\n",
    "\n",
    "# prepare for knn\n",
    "if len(feat_rlvt) > 1:\n",
    "    ind_center_ctr = ind_center_ctr.values.reshape(1, -1)\n",
    "    ind_center_tst = ind_center_tst.values.reshape(1, -1)\n",
    "else:\n",
    "    ind_center_ctr = ind_center_ctr.values.reshape(-1, 1)\n",
    "    ind_center_tst = ind_center_tst.values.reshape(-1, 1)\n",
    "\n",
    "print(ind_center_ctr)\n",
    "print(ind_center_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Control Group for ind\n",
    "\n",
    "# NOTE: by default, the control group search space will include ind, which will appear as a neighbor (distrance will be 0.0)\n",
    "knn_1 = NearestNeighbors(n_neighbors = n + 1, algorithm='ball_tree', metric = d).fit(search_ctr_group[feat_rlvt])\n",
    "knn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_1, indices_1 = knn_1.kneighbors(ind_center_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ctr_df = pd.DataFrame()\n",
    "temp_ctr_df['knn_indices'] = pd.Series(indices_1[0])\n",
    "temp_ctr_df['knn_distances'] = pd.Series(distances_1[0])\n",
    "temp_ctr_df.sort_values(by='knn_distances', ascending=True, inplace=True)\n",
    "\n",
    "# HERE we can drop neighbors based on the distance!\n",
    "temp_ctr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL knn_indices are the same wrt the search space but not wrt org input\n",
    "temp_ctr_df = temp_ctr_df.merge(search_ctr_group[['org_index']], how='inner', left_on='knn_indices', right_index=True)\n",
    "\n",
    "temp_ctr_df\n",
    "\n",
    "# todo: we can. e.g., test on the features of interest as well for ST!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's not drop it for now...\n",
    "# drop ind for ctr! org index is the one we are using to loop over the search space!!! | TODO should I keep the center?\n",
    "# temp_ctr_df = temp_ctr_df[temp_ctr_df['org_index'] != ind].reset_index(drop=True)\n",
    "\n",
    "# temp_ctr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if temp_ctr_df.shape[0] > n:\n",
    "#     print(temp_ctr_df.shape)\n",
    "#     temp_ctr_df.drop(temp_ctr_df.tail(1).index,inplace=True)\n",
    "#     print(temp_ctr_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it\n",
    "temp_dict_df_neighbors['control'] = temp_ctr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "del ind_center_ctr, knn_1, temp_ctr_df, indices_1, distances_1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Test Group for ind\n",
    "\n",
    "temp_search_tst_group = search_tst_group.iloc[[ind] + non_protected_indices].copy()\n",
    "temp_search_tst_group.reset_index(inplace=True, )\n",
    "temp_search_tst_group.rename(columns={'index': 'org_index'}, inplace=True)\n",
    "\n",
    "temp_search_tst_group.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_2 = NearestNeighbors(n_neighbors = n + 1, algorithm='ball_tree', metric = d).fit(temp_search_tst_group[feat_rlvt])\n",
    "knn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_2, indices_2 = knn_2.kneighbors(ind_center_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tst_df = pd.DataFrame()\n",
    "temp_tst_df['knn_indices'] = pd.Series(indices_2[0])\n",
    "temp_tst_df['knn_distances'] = pd.Series(distances_2[0])\n",
    "temp_tst_df.sort_values(by='knn_distances', ascending=True, inplace=True)\n",
    "\n",
    "# HERE we can drop neighbors based on the distance!\n",
    "temp_tst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL knn_indices are the same wrt the search space but not wrt org input\n",
    "# we can uss the knn_indices to get the rest of information\n",
    "temp_tst_df = temp_tst_df.merge(temp_search_tst_group[['org_index']], how='inner', left_on='knn_indices', right_index=True)\n",
    "\n",
    "temp_tst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it\n",
    "temp_dict_df_neighbors['test'] = temp_tst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "del ind_center_tst, knn_2, temp_tst_df, indices_2, distances_2, temp_search_tst_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict_df_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... later on\n",
    "dict_df_neighbors[ind] = temp_dict_df_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall that ind is the same across df and cf_df\n",
    "dict_df_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cf_situation_testing import get_k_neighbors, get_wald_ci\n",
    "\n",
    "feat_trgt = 'LoanApproval'\n",
    "feat_trgt_vals = {'pos': 1, 'neg': -1}\n",
    "# feat_rlvt = ['AnnualSalary']\n",
    "feat_rlvt = ['AnnualSalary', 'AccountBalance']\n",
    "feat_prot = 'Gender'\n",
    "feat_prot_vals = {'non_protected': 0, 'protected': 1}\n",
    "n = 10 # determine by power analysis? (future extension)\n",
    "d = 'manhattan' # ‘manhattan’ - see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html\n",
    "weights = None\n",
    "# weights = {'AnnualSalary': 5, 'AccountBalance': 1}\n",
    "standardize = True\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature LoanApproval with values {'pos': 1, 'neg': -1}\n",
      "protected feature Gender with values {'non_protected': 0, 'protected': 1}\n",
      "with relevant features ['AnnualSalary', 'AccountBalance']\n",
      "all features: ['LoanApproval', 'AnnualSalary', 'AccountBalance', 'Gender']\n",
      "standardizing\n"
     ]
    }
   ],
   "source": [
    "dict_df_neighbors = get_k_neighbors(df=df, cf_df=cf_df, \n",
    "                                    k=n, \n",
    "                                    feat_trgt=feat_trgt, feat_trgt_vals=feat_trgt_vals, \n",
    "                                    feat_rlvt=feat_rlvt, \n",
    "                                    feat_prot=feat_prot, feat_prot_vals=feat_prot_vals, \n",
    "                                    standardize=True, \n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disc = get_wald_ci(dict_df_neighbors=dict_df_neighbors,\n",
    "                       feat_trgt=feat_trgt, feat_trgt_vals=feat_trgt_vals,\n",
    "                       alpha=alpha,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>org_diff</th>\n",
       "      <th>d_alpha</th>\n",
       "      <th>diff</th>\n",
       "      <th>CIs</th>\n",
       "      <th>cfST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.227931</td>\n",
       "      <td>0.590251</td>\n",
       "      <td>[0.5902508705143656, 1.0461127658492708]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>4918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>4946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>4958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>4973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>4978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      individual        p1   p2  org_diff   d_alpha      diff  \\\n",
       "4              9  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "14            44  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "15            47  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "17            50  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "19            55  0.818182  0.0     0.818  0.227931  0.590251   \n",
       "...          ...       ...  ...       ...       ...       ...   \n",
       "1691        4918  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "1697        4946  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "1700        4958  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "1703        4973  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "1705        4978  1.000000  0.0     1.000  0.000000  1.000000   \n",
       "\n",
       "                                           CIs cfST  \n",
       "4                                   [1.0, 1.0]  Yes  \n",
       "14                                  [1.0, 1.0]  Yes  \n",
       "15                                  [1.0, 1.0]  Yes  \n",
       "17                                  [1.0, 1.0]  Yes  \n",
       "19    [0.5902508705143656, 1.0461127658492708]  Yes  \n",
       "...                                        ...  ...  \n",
       "1691                                [1.0, 1.0]  Yes  \n",
       "1697                                [1.0, 1.0]  Yes  \n",
       "1700                                [1.0, 1.0]  Yes  \n",
       "1703                                [1.0, 1.0]  Yes  \n",
       "1705                                [1.0, 1.0]  Yes  \n",
       "\n",
       "[427 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_disc[test_disc['cfST'] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) We need to start testing each group: do now for ind\n",
    "\n",
    "\n",
    "ind = 0\n",
    "int(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctr_group = dict_df_neighbors[ind]['control']\n",
    "# ctr_group = ctr_group.merge(df[feat_list], how='inner', left_on='org_index', right_index=True)\n",
    "\n",
    "ctr_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind ... need to merge with df and cf_df for rest of features:\n",
    "tst_group = dict_df_neighbors[ind]['test']\n",
    "# ctr_group = ctr_group.merge(df[feat_list], how='inner', left_on='org_index', right_index=True)\n",
    "\n",
    "tst_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=ctr_group.shape[0]\n",
    "print(k1)\n",
    "k2=tst_group.shape[0]\n",
    "print(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_group[ctr_group[feat_trgt]==feat_trgt_vals['neg']].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ctr_group[ctr_group[feat_trgt]==feat_trgt_vals['neg']].shape[0] / ctr_group.shape[0]\n",
    "print(p1)\n",
    "p2 = tst_group[tst_group[feat_trgt]==feat_trgt_vals['neg']].shape[0] / tst_group.shape[0]\n",
    "print(p2)\n",
    "\n",
    "diff = p1 - p2\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wald_ci(alpha: float, p1: float, p2: float, k1: int, k2: int):\n",
    "    \n",
    "    wald_ci_summary = {}\n",
    "    \n",
    "    z_score = round(st.norm.ppf(1 - (alpha/2)), 2)\n",
    "    d_alpha = z_score * math.sqrt( (p1*(1 - p1)/k1) + (p2*(1 - p2)/k2) )\n",
    "    \n",
    "    wald_ci_summary['d_alpha'] = d_alpha\n",
    "    wald_ci_summary['CIs'] = [(p1 - p2) - d_alpha, (p1 - p2) + d_alpha]\n",
    "    if (p1 - p2) >= 0:\n",
    "        wald_ci_summary['diff'] = max(0, p1 - p2 - d_alpha)\n",
    "    else:\n",
    "        wald_ci_summary['diff'] = min(0, p1 - p2 + d_alpha)\n",
    "    \n",
    "    print(wald_ci_summary)\n",
    "    \n",
    "    return wald_ci_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_wald_ci = get_wald_ci(alpha=alpha, p1=p1, p2=p2, k1=ctr_group.shape[0], k2=tst_group.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: what's the output for the ST: yes/no where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for p in game.players.passing():\n",
    "    d.append(\n",
    "        {\n",
    "            'Player': p,\n",
    "            'Team': p.team,\n",
    "            'Passer Rating':  p.passer_rating()\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ind)\n",
    "print(ind_wald_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i guess i need some sort of threshold here???\n",
    "diff_epsilon = 0.05 # tau in the second paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ind_wald_ci['diff'] > diff_epsilon:\n",
    "    ind_wald_ci['cfST'] = 'Yes'\n",
    "else:\n",
    "    ind_wald_ci['cfST'] = 'No'\n",
    "    \n",
    "#how to return the results? get df with discrimination columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.random_sample((10, 3))\n",
    "print(X)\n",
    "print('---')\n",
    "print(X[:1])\n",
    "tree = BallTree(X, leaf_size=2)              \n",
    "dist, ind = tree.query(X[:1], k=3)                \n",
    "print(ind)  # indices of 3 closest neighbors\n",
    "#[0 3 1]\n",
    "print(dist)  # distances to 3 closest neighbors\n",
    "#[ 0.          0.19662693  0.29473397]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
