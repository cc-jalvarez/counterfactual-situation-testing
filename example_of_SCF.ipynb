{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example script where we try to understand Pearl's structural counterfactuals (SCF) generation process (abduction - action - prediction) in the context of situation testing (SI). We want to be able to take a factual tuple {x^F} and return it's counterfactual by changing (only?) the protected attribute A from a^F=a to a^CF=a'. We believe to have two clear scenarios here regarding the latent space (or exogenous variables): either we have them by having generated ourselves the data or we don't and most estimate them using, e.g., MCMC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall params\n",
    "random.seed(2022)\n",
    "n = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1 from Karimi et al. (2020)\n",
    "With the DAG: X1->Y, X1->X2, X->Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = 10000*np.random.poisson(lam=10, size=n)\n",
    "u2 = 2500*np.random.normal(loc=0.0, scale=1.0, size=n)\n",
    "\n",
    "# annual salary\n",
    "x1 = u1\n",
    "# account balance\n",
    "x2 = (3/10)*x1 + u2\n",
    "# loan approval\n",
    "y = np.sign(x1 + 5*x2 - 225000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([412.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 588.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARc0lEQVR4nO3da4wdZ33H8e8Pm4RyjxvbuLGLg2RRnKoh0coNpKJQI+KEgtMXkYxa6raRLKRQgdSL7FZqqZClUKmordQguSGt21Isi0tjhatriFBLSdiE3BzH2CEh2drYS7j3RWjCvy/OuDqxz+6e3T3HTh6+H2k1M888z8x/54x/Ozt7zjhVhSSpLc871wVIkkbPcJekBhnuktQgw12SGmS4S1KDlp7rAgAuvPDCWrt27bkuQ5KeU+66665vV9XyQeueFeG+du1aJicnz3UZkvSckuSbM63ztowkNWiocE/y8iQfS/JQkkNJXpdkWZL9SY500wv6+u9IcjTJ4SRXja98SdIgw165/w3w2ar6BeBS4BCwHThQVeuAA90ySdYDW4BLgE3ATUmWjLpwSdLM5gz3JC8F3gB8GKCqflxV3wM2A7u7bruBa7v5zcCeqnqyqh4BjgIbRlu2JGk2w1y5vwqYBv4hydeS3JzkRcDKqjoO0E1XdP0vAh7vGz/VtT1Dkm1JJpNMTk9PL+qbkCQ90zDhvhS4HPhQVV0G/A/dLZgZZEDbGU8nq6pdVTVRVRPLlw98J48kaYGGCfcpYKqq7uiWP0Yv7E8kWQXQTU/29V/TN341cGw05UqShjFnuFfVt4DHk7y6a9oIPAjsA7Z2bVuBW7v5fcCWJOcnuRhYB9w50qolSbMa9kNMvw98JMl5wDeA36X3g2FvkuuBx4DrAKrqYJK99H4APAXcUFVPj7xySdKMhgr3qroHmBiwauMM/XcCOxdeliSdPWu3f+qc7fvRG986lu36CVVJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUFDhXuSR5Pcn+SeJJNd27Ik+5Mc6aYX9PXfkeRoksNJrhpX8ZKkweZz5f6mqnptVU10y9uBA1W1DjjQLZNkPbAFuATYBNyUZMkIa5YkzWExt2U2A7u7+d3AtX3te6rqyap6BDgKbFjEfiRJ8zRsuBfw+SR3JdnWta2squMA3XRF134R8Hjf2Kmu7RmSbEsymWRyenp6YdVLkgZaOmS/K6vqWJIVwP4kD83SNwPa6oyGql3ALoCJiYkz1kuSFm6oK/eqOtZNTwKfpHeb5USSVQDd9GTXfQpY0zd8NXBsVAVLkuY2Z7gneVGSl5yaB94CPADsA7Z23bYCt3bz+4AtSc5PcjGwDrhz1IVLkmY2zG2ZlcAnk5zq/69V9dkkXwX2JrkeeAy4DqCqDibZCzwIPAXcUFVPj6V6SdJAc4Z7VX0DuHRA+xPAxhnG7AR2Lro6SdKC+AlVSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQ0nNdwCis3f6pc7LfR2986znZryTNZegr9yRLknwtyW3d8rIk+5Mc6aYX9PXdkeRoksNJrhpH4ZKkmc3ntsx7gEN9y9uBA1W1DjjQLZNkPbAFuATYBNyUZMloypUkDWOocE+yGngrcHNf82Zgdze/G7i2r31PVT1ZVY8AR4ENI6lWkjSUYa/c/xr4Y+AnfW0rq+o4QDdd0bVfBDze12+qa3uGJNuSTCaZnJ6enm/dkqRZzBnuSX4dOFlVdw25zQxoqzMaqnZV1URVTSxfvnzITUuShjHMu2WuBN6e5BrgBcBLk/wLcCLJqqo6nmQVcLLrPwWs6Ru/Gjg2yqIlSbOb88q9qnZU1eqqWkvvD6VfqKrfAvYBW7tuW4Fbu/l9wJYk5ye5GFgH3DnyyiVJM1rM+9xvBPYmuR54DLgOoKoOJtkLPAg8BdxQVU8vulJJ0tDmFe5VdTtwezf/BLBxhn47gZ2LrE2StEA+fkCSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KD5gz3JC9IcmeSe5McTPIXXfuyJPuTHOmmF/SN2ZHkaJLDSa4a5zcgSTrTMFfuTwK/VlWXAq8FNiW5AtgOHKiqdcCBbpkk64EtwCXAJuCmJEvGULskaQZzhnv1/KhbfH73VcBmYHfXvhu4tpvfDOypqier6hHgKLBhlEVLkmY31D33JEuS3AOcBPZX1R3Ayqo6DtBNV3TdLwIe7xs+1bWdvs1tSSaTTE5PTy/iW5AknW6ocK+qp6vqtcBqYEOSX5ylewZtYsA2d1XVRFVNLF++fKhiJUnDmde7Zarqe8Dt9O6ln0iyCqCbnuy6TQFr+oatBo4ttlBJ0vCGebfM8iQv7+Z/Bngz8BCwD9jaddsK3NrN7wO2JDk/ycXAOuDOEdctSZrF0iH6rAJ2d+94eR6wt6puS/JfwN4k1wOPAdcBVNXBJHuBB4GngBuq6unxlC9JGmTOcK+q+4DLBrQ/AWycYcxOYOeiq5MkLYifUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgOcM9yZokX0xyKMnBJO/p2pcl2Z/kSDe9oG/MjiRHkxxOctU4vwFJ0pmGuXJ/CviDqnoNcAVwQ5L1wHbgQFWtAw50y3TrtgCXAJuAm5IsGUfxkqTB5gz3qjpeVXd38z8EDgEXAZuB3V233cC13fxmYE9VPVlVjwBHgQ0jrluSNIt53XNPsha4DLgDWFlVx6H3AwBY0XW7CHi8b9hU13b6trYlmUwyOT09vYDSJUkzGTrck7wY+Djw3qr6wWxdB7TVGQ1Vu6pqoqomli9fPmwZkqQhDBXuSZ5PL9g/UlWf6JpPJFnVrV8FnOzap4A1fcNXA8dGU64kaRjDvFsmwIeBQ1X1wb5V+4Ct3fxW4Na+9i1Jzk9yMbAOuHN0JUuS5rJ0iD5XAu8E7k9yT9f2J8CNwN4k1wOPAdcBVNXBJHuBB+m90+aGqnp61IVLkmY2Z7hX1X8w+D46wMYZxuwEdi6iLknSIvgJVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ2aM9yT3JLkZJIH+tqWJdmf5Eg3vaBv3Y4kR5McTnLVuAqXJM1smCv3fwQ2nda2HThQVeuAA90ySdYDW4BLujE3JVkysmolSUOZM9yr6kvAd05r3gzs7uZ3A9f2te+pqier6hHgKLBhNKVKkoa10HvuK6vqOEA3XdG1XwQ83tdvqmuTJJ1Fo/6Daga01cCOybYkk0kmp6enR1yGJP10W2i4n0iyCqCbnuzap4A1ff1WA8cGbaCqdlXVRFVNLF++fIFlSJIGWWi47wO2dvNbgVv72rckOT/JxcA64M7FlShJmq+lc3VI8lHgjcCFSaaAPwduBPYmuR54DLgOoKoOJtkLPAg8BdxQVU+PqXZJ0gzmDPeqescMqzbO0H8nsHMxRUmSFsdPqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRpbuCfZlORwkqNJto9rP5KkM40l3JMsAf4OuBpYD7wjyfpx7EuSdKZxXblvAI5W1Teq6sfAHmDzmPYlSTrN0jFt9yLg8b7lKeCX+zsk2QZs6xZ/lOTwIvZ3IfDtRYxfkHxgzi7npK4hWNf8WNf8WNc85AOLquuVM60YV7hnQFs9Y6FqF7BrJDtLJqtqYhTbGiXrmh/rmh/rmp+ftrrGdVtmCljTt7waODamfUmSTjOucP8qsC7JxUnOA7YA+8a0L0nSacZyW6aqnkrybuBzwBLglqo6OI59dUZye2cMrGt+rGt+rGt+fqrqSlXN3UuS9JziJ1QlqUGGuyQ16DkR7kmuS3IwyU+SzPiWoZkeeZBkWZL9SY500wtGVNec203y6iT39H39IMl7u3XvS/LffeuuOVt1df0eTXJ/t+/J+Y4fR11J1iT5YpJD3Wv+nr51Iz1ecz0iIz1/262/L8nlw44dc12/2dVzX5IvJ7m0b93A1/Qs1fXGJN/ve33+bNixY67rj/pqeiDJ00mWdevGebxuSXIyyQMzrB/v+VVVz/ov4DXAq4HbgYkZ+iwBHgZeBZwH3Aus79b9JbC9m98OfGBEdc1ru12N3wJe2S2/D/jDMRyvoeoCHgUuXOz3Ncq6gFXA5d38S4Cv972OIztes50vfX2uAT5D73MbVwB3DDt2zHW9Hrigm7/6VF2zvaZnqa43ArctZOw46zqt/9uAL4z7eHXbfgNwOfDADOvHen49J67cq+pQVc31CdbZHnmwGdjdze8Grh1RafPd7kbg4ar65oj2P5PFfr/n7HhV1fGqurub/yFwiN4nnkdtmEdkbAb+qXq+Arw8yaohx46trqr6clV9t1v8Cr3PkYzbYr7nc3q8TvMO4KMj2vesqupLwHdm6TLW8+s5Ee5DGvTIg1OhsLKqjkMvPIAVI9rnfLe7hTNPrHd3v5LdMqrbH/Ooq4DPJ7krvcdBzHf8uOoCIMla4DLgjr7mUR2v2c6XufoMM3acdfW7nt7V3ykzvaZnq67XJbk3yWeSXDLPseOsiyQvBDYBH+9rHtfxGsZYz69xPX5g3pL8O/CKAav+tKpuHWYTA9oW/T7P2eqa53bOA94O7Ohr/hDwfnp1vh/4K+D3zmJdV1bVsSQrgP1JHuquNhZshMfrxfT+Eb63qn7QNS/4eA3axYC208+XmfqM5VybY59ndkzeRC/cf6WveeSv6TzqupveLccfdX8P+Tdg3ZBjx1nXKW8D/rOq+q+mx3W8hjHW8+tZE+5V9eZFbmK2Rx6cSLKqqo53v/acHEVdSeaz3auBu6vqRN+2/38+yd8Dt53NuqrqWDc9meST9H4d/BLn+HgleT69YP9IVX2ib9sLPl4DDPOIjJn6nDfE2HHWRZJfAm4Grq6qJ061z/Kajr2uvh/CVNWnk9yU5MJhxo6zrj5n/OY8xuM1jLGeXy3dlpntkQf7gK3d/FZgmN8EhjGf7Z5xr68LuFN+Axj4V/Vx1JXkRUlecmoeeEvf/s/Z8UoS4MPAoar64GnrRnm8hnlExj7gt7t3NVwBfL+7nTTOx2vMue0kPw98AnhnVX29r3221/Rs1PWK7vUjyQZ6+fLEMGPHWVdXz8uAX6XvnBvz8RrGeM+vcfyVeNRf9P4hTwFPAieAz3XtPwd8uq/fNfTeXfEwvds5p9p/FjgAHOmmy0ZU18DtDqjrhfRO8pedNv6fgfuB+7oXb9XZqoveX+Lv7b4OPluOF71bDNUdk3u6r2vGcbwGnS/Au4B3dfOh95/OPNztd2K2sSM83+eq62bgu33HZ3Ku1/Qs1fXubr/30vtD7+ufDcerW/4dYM9p48Z9vD4KHAf+l15+XX82zy8fPyBJDWrptowkqWO4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb9HxUMm+I9GdKEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the factual distribution\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>U1_hat</th>\n",
       "      <th>U2_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>28959.229435</td>\n",
       "      <td>80000</td>\n",
       "      <td>4959.229435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>60000</td>\n",
       "      <td>19167.894829</td>\n",
       "      <td>60000</td>\n",
       "      <td>1167.894829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>26439.781762</td>\n",
       "      <td>80000</td>\n",
       "      <td>2439.781762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>90000</td>\n",
       "      <td>32479.002130</td>\n",
       "      <td>90000</td>\n",
       "      <td>5479.002130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>40095.329960</td>\n",
       "      <td>120000</td>\n",
       "      <td>4095.329960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>70000</td>\n",
       "      <td>18357.988615</td>\n",
       "      <td>70000</td>\n",
       "      <td>-2642.011385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>23227.399615</td>\n",
       "      <td>80000</td>\n",
       "      <td>-772.600385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>25751.746805</td>\n",
       "      <td>100000</td>\n",
       "      <td>-4248.253195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>36228.660833</td>\n",
       "      <td>120000</td>\n",
       "      <td>228.660833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110000</td>\n",
       "      <td>29841.984164</td>\n",
       "      <td>110000</td>\n",
       "      <td>-3158.015836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y      X1            X2  U1_hat       U2_hat\n",
       "0 -1.0   80000  28959.229435   80000  4959.229435\n",
       "1 -1.0   60000  19167.894829   60000  1167.894829\n",
       "2 -1.0   80000  26439.781762   80000  2439.781762\n",
       "3  1.0   90000  32479.002130   90000  5479.002130\n",
       "4  1.0  120000  40095.329960  120000  4095.329960\n",
       "5 -1.0   70000  18357.988615   70000 -2642.011385\n",
       "6 -1.0   80000  23227.399615   80000  -772.600385\n",
       "7  1.0  100000  25751.746805  100000 -4248.253195\n",
       "8  1.0  120000  36228.660833  120000   228.660833\n",
       "9  1.0  110000  29841.984164  110000 -3158.015836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataset for the observables*\n",
    "# *include unobservables too... here, imagine you ran the MCMC before and estimated u|evidence\n",
    "d = {'Y': y, 'X1': x1, 'X2': x2, 'U1_hat': u1, 'U2_hat': u2}\n",
    "data = pd.DataFrame(d)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # consider the individual with x1=75,000 and x2=25,000\n",
    "# y_if = np.sign(75000 + 5*25000 - 225000)\n",
    "# y_if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y             1.00000\n",
       "X1        90000.00000\n",
       "X2        32479.00213\n",
       "U1_hat    90000.00000\n",
       "U2_hat     5479.00213\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider individual i: what is the counterfactual of y_i?\n",
    "# here, in ST, want the STRUCTURAL COUNTERFACTUAL x_scf, not too interested in y_scf\n",
    "# because want to match x_scf with those that don't share the protected attribute memebership of i\n",
    "i = 3\n",
    "data.loc[i, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "5479.00212963756\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Abduction\n",
    "# Get U's given the evidence X's [assuming causal sufficiency and, ofc, a known causal graph]\n",
    "\n",
    "# u1 given x1: from Fig.1, x1 = u1 and thus u1 = x1\n",
    "u1_i = data.loc[i, 'X1']\n",
    "print(u1_i)\n",
    "\n",
    "# u2 given x2: from Fig.1, x2 = (3/10)*x1 + u2 and thus u2 = x2 - (3/10)*x1\n",
    "u2_i = data.loc[i, 'X2'] - (3/10)*data.loc[i, 'X1']\n",
    "print(u2_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95000\n",
      "33979.00212963756\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Action\n",
    "# Given the SCM, intervene it accordingly using the do-operator \n",
    "delta = 5000\n",
    "\n",
    "# Org SCM M:\n",
    "# x1 = u1             [salary]\n",
    "# x2 = (3/10)*x1 + u2 [balance]\n",
    "\n",
    "# do(X1 := X1 + delta), then M':\n",
    "# X1' := X1 + delta\n",
    "# X2 = (3/10)*X1' + U2\n",
    "\n",
    "# Step 3: Prediction (notice at at i-level)\n",
    "# Apply the chagnes on M' and get the scf tuple \n",
    "\n",
    "x1_i_scf = data.loc[i, 'X1'] + delta\n",
    "print(x1_i_scf)\n",
    "\n",
    "x2_i_scf = (3/10)*x1_i_scf + u2_i\n",
    "print(x2_i_scf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[i, 'Y'])\n",
    "# vs\n",
    "print(np.sign(x1_i_scf + 5*x2_i_scf - 225000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This abduction-action-prediction from Karimi et al. is very usful for situation testing because all the focus is on profucing the structural counterfactual tuple for the attribute space; we don't 'care' for Y!\n",
    "\n",
    "This means, wrt to ST, that we can generate X_CF without having to know the decision-maker (i.e., model agnostic). Ofc, the assumption here is that we have a SCM model that is known. Further more, SCM needs to be estimated to obtain the functional form for carrying out the three steps... meaning that we further have to assume (potentially) (1) causal sufficiency and (2) additive noise models for a nice estimation. Although these are considerable assumptions, it's standard within the literature.\n",
    "\n",
    "ST simplifies this step in that we only care about switching the protected attribute A, which is usually 0 or 1. Further, we are not interested in flipping the decision, but in checking whether the decision flips or not!\n",
    "\n",
    "Furthermore, we should consider the types of potential interventions presented in this paper... and extend situation testing beyond flipping A?!\n",
    "\n",
    "Given {x^F}, we can generate {x^SCF} and from this generated tuple try to match individuals that don't share the protected attribute of the complainant... creating out counterfactual group.\n",
    "\n",
    "In practice, we won't have access to U (i.e., the latent space) but we can approximated using MCMC (like in Kusner at al.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1 with $A$\n",
    "with the DAG: X1->Y, X1->X2, X->Y, A->X1, A->X2 such that $A$ is gender (A=1 female, A=0 male)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([665.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 335.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP3UlEQVR4nO3cf6xfd13H8eeLlg3kh+vcbdO0xRZTgc44wGudogSocWUYOxOWFBUasqQxToKJiXT8ITGmyfjHoNFJmoHUCDQNP1wFRZviRAOs3MnY1pW664btTet6GSKCyUjL2z/uwXzX3tt72vv93sv99PlImnPO53zO97zfuTev7+m53+9JVSFJastzlroASdLwGe6S1CDDXZIaZLhLUoMMd0lq0MqlLgDghhtuqI0bNy51GZK0rDz44INfr6qx2fb9QIT7xo0bmZiYWOoyJGlZSfIfc+3ztowkNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXoB+Ibqgu1cc+nl+S8X7v7TUtyXkmaj1fuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG9Qr3JNcl+ViSryY5nuRnk1yf5HCSx7vlqoH5dyWZTHIiyS2jK1+SNJu+V+5/DHymql4O3AQcB/YAR6pqM3Ck2ybJFmAncCOwHbgnyYphFy5Jmtu84Z7kxcBrgQ8AVNV3q+qbwA5gfzdtP3Bbt74DOFBVz1TVk8AksHW4ZUuSLqXPlftLgWngL5J8Ocm9SV4ArKmqMwDdcnU3fx1wauD4qW7sWZLsTjKRZGJ6enpBTUiSnq1PuK8EXg38eVW9CvgO3S2YOWSWsbpooGpfVY1X1fjY2FivYiVJ/fQJ9ylgqqoe6LY/xkzYP5VkLUC3PDswf8PA8euB08MpV5LUx7zhXlX/CZxK8rJuaBvwGHAI2NWN7QLu69YPATuTXJtkE7AZODrUqiVJl7Sy57x3AB9Ocg3wBPB2Zt4YDia5AzgJ3A5QVceSHGTmDeAccGdVnR965ZKkOfUK96p6CBifZde2OebvBfZeeVmSpIXwG6qS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBvcI9ydeSPJLkoSQT3dj1SQ4nebxbrhqYf1eSySQnktwyquIlSbO7nCv311fVK6tqvNveAxypqs3AkW6bJFuAncCNwHbgniQrhlizJGkeC7ktswPY363vB24bGD9QVc9U1ZPAJLB1AeeRJF2mvuFewD8keTDJ7m5sTVWdAeiWq7vxdcCpgWOnurFnSbI7yUSSienp6SurXpI0q5U9572mqk4nWQ0cTvLVS8zNLGN10UDVPmAfwPj4+EX7JUlXrteVe1Wd7pZngU8yc5vlqSRrAbrl2W76FLBh4PD1wOlhFSxJmt+84Z7kBUle9P114JeAR4FDwK5u2i7gvm79ELAzybVJNgGbgaPDLlySNLc+t2XWAJ9M8v35H6mqzyT5EnAwyR3ASeB2gKo6luQg8BhwDrizqs6PpHpJ0qzmDfeqegK4aZbxp4FtcxyzF9i74OokSVfEb6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG9Q73JCuSfDnJp7rt65McTvJ4t1w1MPeuJJNJTiS5ZRSFS5LmdjlX7u8Ejg9s7wGOVNVm4Ei3TZItwE7gRmA7cE+SFcMpV5LUR69wT7IeeBNw78DwDmB/t74fuG1g/EBVPVNVTwKTwNahVCtJ6qXvlfv7gN8DvjcwtqaqzgB0y9Xd+Drg1MC8qW7sWZLsTjKRZGJ6evpy65YkXcK84Z7kl4GzVfVgz9fMLGN10UDVvqoar6rxsbGxni8tSepjZY85rwF+JcmtwPOAFyf5K+CpJGur6kyStcDZbv4UsGHg+PXA6WEWLUm6tHmv3KvqrqpaX1UbmflD6Wer6jeAQ8Cubtou4L5u/RCwM8m1STYBm4GjQ69ckjSnPlfuc7kbOJjkDuAkcDtAVR1LchB4DDgH3FlV5xdcqSSpt8sK96q6H7i/W38a2DbHvL3A3gXWJkm6Qn5DVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aCHPc5ekJmzc8+klO/fX7n7TSF7XK3dJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkho0b7gneV6So0m+kuRYkj/oxq9PcjjJ491y1cAxdyWZTHIiyS2jbECSdLE+V+7PAG+oqpuAVwLbk9wM7AGOVNVm4Ei3TZItwE7gRmA7cE+SFSOoXZI0h3nDvWZ8u9t8bvevgB3A/m58P3Bbt74DOFBVz1TVk8AksHWYRUuSLq3XPfckK5I8BJwFDlfVA8CaqjoD0C1Xd9PXAacGDp/qxi58zd1JJpJMTE9PL6AFSdKFeoV7VZ2vqlcC64GtSX7iEtMz20vM8pr7qmq8qsbHxsZ6FStJ6ueyPi1TVd8E7mfmXvpTSdYCdMuz3bQpYMPAYeuB0wstVJLUX59Py4wlua5bfz7wi8BXgUPArm7aLuC+bv0QsDPJtUk2AZuBo0OuW5J0CX0e+bsW2N994uU5wMGq+lSSLwAHk9wBnARuB6iqY0kOAo8B54A7q+r8aMqXJM1m3nCvqoeBV80y/jSwbY5j9gJ7F1ydJOmK+A1VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoHnDPcmGJP+Y5HiSY0ne2Y1fn+Rwkse75aqBY+5KMpnkRJJbRtmAJOlifa7czwG/W1WvAG4G7kyyBdgDHKmqzcCRbptu307gRmA7cE+SFaMoXpI0u3nDvarOVNW/duv/AxwH1gE7gP3dtP3Abd36DuBAVT1TVU8Ck8DWIdctSbqEy7rnnmQj8CrgAWBNVZ2BmTcAYHU3bR1wauCwqW5MkrRIeod7khcCHwd+p6q+damps4zVLK+3O8lEkonp6em+ZUiSeugV7kmey0ywf7iqPtENP5Vkbbd/LXC2G58CNgwcvh44feFrVtW+qhqvqvGxsbErrV+SNIs+n5YJ8AHgeFX90cCuQ8Cubn0XcN/A+M4k1ybZBGwGjg6vZEnSfFb2mPMa4K3AI0ke6sbeDdwNHExyB3ASuB2gqo4lOQg8xswnbe6sqvPDLlySNLd5w72q/oXZ76MDbJvjmL3A3gXUJUlaAL+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGjRvuCf5YJKzSR4dGLs+yeEkj3fLVQP77koymeREkltGVbgkaW59rtw/BGy/YGwPcKSqNgNHum2SbAF2Ajd2x9yTZMXQqpUk9TJvuFfV54BvXDC8A9jfre8HbhsYP1BVz1TVk8AksHU4pUqS+rrSe+5rquoMQLdc3Y2vA04NzJvqxiRJi2jYf1DNLGM168Rkd5KJJBPT09NDLkOSrm5XGu5PJVkL0C3PduNTwIaBeeuB07O9QFXtq6rxqhofGxu7wjIkSbO50nA/BOzq1ncB9w2M70xybZJNwGbg6MJKlCRdrpXzTUjyUeB1wA1JpoD3AHcDB5PcAZwEbgeoqmNJDgKPAeeAO6vq/IhqlyTNYd5wr6q3zLFr2xzz9wJ7F1KUJGlh/IaqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0aWbgn2Z7kRJLJJHtGdR5J0sVGEu5JVgB/BrwR2AK8JcmWUZxLknSxUV25bwUmq+qJqvoucADYMaJzSZIusHJEr7sOODWwPQX8zOCEJLuB3d3mt5OcWMD5bgC+voDjr0jeu9hn/H9L0u8Ss+erw1XXc967oJ5/dK4dowr3zDJWz9qo2gfsG8rJkomqGh/Gay0HV1u/YM9XC3senlHdlpkCNgxsrwdOj+hckqQLjCrcvwRsTrIpyTXATuDQiM4lSbrASG7LVNW5JL8N/D2wAvhgVR0bxbk6Q7m9s4xcbf2CPV8t7HlIUlXzz5IkLSt+Q1WSGmS4S1KDlk24z/c4g8z4k27/w0levRR1DlOPnn+96/XhJJ9PctNS1DlMfR9bkeSnk5xP8ubFrG8U+vSc5HVJHkpyLMk/LXaNw9bjd/uHk/xNkq90Pb99KeocliQfTHI2yaNz7B9+flXVD/w/Zv4o++/AS4FrgK8AWy6Ycyvwd8x8xv5m4IGlrnsRev45YFW3/saroeeBeZ8F/hZ481LXvQg/5+uAx4CXdNurl7ruRej53cB7u/Ux4BvANUtd+wJ6fi3wauDROfYPPb+Wy5V7n8cZ7AD+smZ8EbguydrFLnSI5u25qj5fVf/VbX6Rme8TLGd9H1vxDuDjwNnFLG5E+vT8a8AnquokQFUt97779FzAi5IEeCEz4X5uccscnqr6HDM9zGXo+bVcwn22xxmsu4I5y8nl9nMHM+/8y9m8PSdZB/wq8P5FrGuU+vycfxxYleT+JA8meduiVTcafXr+U+AVzHz58RHgnVX1vcUpb0kMPb9G9fiBYZv3cQY95ywnvftJ8npmwv3nR1rR6PXp+X3Au6rq/MxF3bLXp+eVwE8B24DnA19I8sWq+rdRFzcifXq+BXgIeAPwY8DhJP9cVd8acW1LZej5tVzCvc/jDFp75EGvfpL8JHAv8MaqenqRahuVPj2PAwe6YL8BuDXJuar660WpcPj6/m5/vaq+A3wnyeeAm4DlGu59en47cHfN3JCeTPIk8HLg6OKUuOiGnl/L5bZMn8cZHALe1v3V+Wbgv6vqzGIXOkTz9pzkJcAngLcu46u4QfP2XFWbqmpjVW0EPgb81jIOduj3u30f8AtJVib5IWaesHp8kescpj49n2TmfyokWQO8DHhiUatcXEPPr2Vx5V5zPM4gyW92+9/PzCcnbgUmgf9l5p1/2erZ8+8DPwLc013Jnqtl/ES9nj03pU/PVXU8yWeAh4HvAfdW1awfqVsOev6c/xD4UJJHmLll8a6qWraPAk7yUeB1wA1JpoD3AM+F0eWXjx+QpAYtl9sykqTLYLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBv0fuEdCAp68RTQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_men = 0.65\n",
    "uA = random.choices(population=[0, 1], weights=[p_men, (1 - p_men)], k=n)\n",
    "plt.hist(uA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u1 = 10000*np.random.poisson(lam=10, size=n)\n",
    "#u2 = 2500*np.random.normal(loc=0.0, scale=1.0, size=n)\n",
    "#uA = see previous cell!\n",
    "\n",
    "# gender \n",
    "A = np.asanyarray(uA)\n",
    "# and its weights (systematic issue) | we avoid direct effects (as it would be ilegal and inline with Hecker's view)\n",
    "beta1 = -9500\n",
    "beta2 = -500\n",
    "\n",
    "# annual salary\n",
    "n_x1 = u1 + beta1*A\n",
    "# account balance\n",
    "n_x2 = (3/10)*n_x1 + u2 + beta2*A\n",
    "# loan approval\n",
    "n_y = np.sign(n_x1 + 5*n_x2 - 225000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([446.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 554.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the factual distribution\n",
    "plt.hist(n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>nY</th>\n",
       "      <th>nX1</th>\n",
       "      <th>nX2</th>\n",
       "      <th>U1_hat</th>\n",
       "      <th>U2_hat</th>\n",
       "      <th>uA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>28959.229435</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>28959.229435</td>\n",
       "      <td>80000</td>\n",
       "      <td>4959.229435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>60000</td>\n",
       "      <td>19167.894829</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>60000</td>\n",
       "      <td>19167.894829</td>\n",
       "      <td>60000</td>\n",
       "      <td>1167.894829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>26439.781762</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>26439.781762</td>\n",
       "      <td>80000</td>\n",
       "      <td>2439.781762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>90000</td>\n",
       "      <td>32479.002130</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90000</td>\n",
       "      <td>32479.002130</td>\n",
       "      <td>90000</td>\n",
       "      <td>5479.002130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>40095.329960</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110500</td>\n",
       "      <td>36745.329960</td>\n",
       "      <td>120000</td>\n",
       "      <td>4095.329960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>70000</td>\n",
       "      <td>18357.988615</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>60500</td>\n",
       "      <td>15007.988615</td>\n",
       "      <td>70000</td>\n",
       "      <td>-2642.011385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>23227.399615</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>23227.399615</td>\n",
       "      <td>80000</td>\n",
       "      <td>-772.600385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>25751.746805</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>25751.746805</td>\n",
       "      <td>100000</td>\n",
       "      <td>-4248.253195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>36228.660833</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110500</td>\n",
       "      <td>32878.660833</td>\n",
       "      <td>120000</td>\n",
       "      <td>228.660833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110000</td>\n",
       "      <td>29841.984164</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100500</td>\n",
       "      <td>26491.984164</td>\n",
       "      <td>110000</td>\n",
       "      <td>-3158.015836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y      X1            X2  Gender   nY     nX1           nX2  U1_hat  \\\n",
       "0 -1.0   80000  28959.229435       0 -1.0   80000  28959.229435   80000   \n",
       "1 -1.0   60000  19167.894829       0 -1.0   60000  19167.894829   60000   \n",
       "2 -1.0   80000  26439.781762       0 -1.0   80000  26439.781762   80000   \n",
       "3  1.0   90000  32479.002130       0  1.0   90000  32479.002130   90000   \n",
       "4  1.0  120000  40095.329960       1  1.0  110500  36745.329960  120000   \n",
       "5 -1.0   70000  18357.988615       1 -1.0   60500  15007.988615   70000   \n",
       "6 -1.0   80000  23227.399615       0 -1.0   80000  23227.399615   80000   \n",
       "7  1.0  100000  25751.746805       0  1.0  100000  25751.746805  100000   \n",
       "8  1.0  120000  36228.660833       1  1.0  110500  32878.660833  120000   \n",
       "9  1.0  110000  29841.984164       1  1.0  100500  26491.984164  110000   \n",
       "\n",
       "        U2_hat  uA  \n",
       "0  4959.229435   0  \n",
       "1  1167.894829   0  \n",
       "2  2439.781762   0  \n",
       "3  5479.002130   0  \n",
       "4  4095.329960   1  \n",
       "5 -2642.011385   1  \n",
       "6  -772.600385   0  \n",
       "7 -4248.253195   0  \n",
       "8   228.660833   1  \n",
       "9 -3158.015836   1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataset for the observables*\n",
    "# *include unobservables too... here, imagine you ran the MCMC before and estimated u|evidence\n",
    "d = {'Y': y, 'X1': x1, 'X2': x2, \n",
    "     'Gender': A, 'nY': n_y, 'nX1': n_x1, 'nX2': n_x2,\n",
    "     'U1_hat': u1, 'U2_hat': u2, 'uA': uA}\n",
    "data = pd.DataFrame(d)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female unbiased\n",
      "0.6119402985074627\n",
      "male unbiased\n",
      "0.5759398496240602\n",
      "female biased\n",
      "0.5104477611940299\n",
      "male biased\n",
      "0.5759398496240602\n"
     ]
    }
   ],
   "source": [
    "# total of females\n",
    "n_f = data[data['Gender']==1].shape[0]\n",
    "# total of males\n",
    "n_m = data[data['Gender']==0].shape[0]\n",
    "\n",
    "# unbiased\n",
    "print('female unbiased')\n",
    "print(data[(data['Gender']==1) & (data['Y']==1)].shape[0] / n_f)\n",
    "print('male unbiased')\n",
    "print(data[(data['Gender']==0) & (data['Y']==1)].shape[0] / n_m)\n",
    "\n",
    "# biased\n",
    "print('female biased')\n",
    "print(data[(data['Gender']==1) & (data['nY']==1)].shape[0] / n_f)\n",
    "print('male biased')\n",
    "print(data[(data['Gender']==0) & (data['nY']==1)].shape[0] / n_m)\n",
    "\n",
    "# TODO: would this show in a trained model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Would this translate into some trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBRegressor, XGBClassifier\n",
    "# from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Y', 'X1', 'X2', 'Gender', 'nY', 'nX1', 'nX2', 'U1_hat', 'U2_hat',\n",
       "       'uA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "u_data = data[['Y', 'X1', 'X2', 'Gender']].copy()\n",
    "print(u_data.shape)\n",
    "\n",
    "b_data = data[['nY', 'nX1', 'nX2', 'Gender']].copy()\n",
    "print(b_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nY  nY2\n",
      "0 -1.0  0.0\n",
      "1 -1.0  0.0\n",
      "2 -1.0  0.0\n",
      "3  1.0  1.0\n",
      "4  1.0  1.0\n",
      "5 -1.0  0.0\n",
      "6 -1.0  0.0\n",
      "7  1.0  1.0\n",
      "8  1.0  1.0\n",
      "9  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# todo: let's do a simple logit here, later we can reuse the FairEncoder code and streamline multiple models\n",
    "# todo: also create an utils files accordingly\n",
    "# todo: get comfortable with Pipeline\n",
    "\n",
    "b_data['nY2'] = np.where(b_data['nY']==-1, 0 ,b_data['nY'])\n",
    "print(b_data[['nY', 'nY2']].head(10))\n",
    "\n",
    "targets = ['nY2', 'nY']\n",
    "y = b_data['nY2']\n",
    "X = b_data.drop(columns=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_tr, y_tr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.75985932e-05,  1.33050693e-04, -3.08062261e+00]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = clf.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[157,  30],\n",
       "       [ 62, 251]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_pr, y_te)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: move later to some utils.py files \n",
    "def calculate_cm(true, preds):\n",
    "    \n",
    "    # Obtain the confusion matrix\n",
    "    cm = confusion_matrix(preds, true)\n",
    "    \n",
    "    # Return all\n",
    "    cm_dict = dict()\n",
    "\n",
    "    #  https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)\n",
    "    cm_dict['FP'] = FP\n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    cm_dict['FN'] = FN\n",
    "    TP = np.diag(cm)\n",
    "    cm_dict['TP'] = TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    cm_dict['TN'] = TN\n",
    "    \n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP / (TP + FN)\n",
    "    cm_dict['TPR'] = TPR\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN / (TN + FP)\n",
    "    cm_dict['TNR'] = TNR\n",
    "    \n",
    "    # todo: expand dict for others\n",
    "    # Precision or positive predictive valbue\n",
    "    PPV = TP / (TP + FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN / (TN + FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP / (FP + TN)\n",
    "    # False negative rate\n",
    "    FNR = FN / (TP + FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP / (TP + FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "    #return cm_dict\n",
    "    return TPR[0] #esto esta bien!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5539568345323741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4460431654676259"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference group (males, or A=0): group 2\n",
    "aux = X_te.copy()\n",
    "aux['target'] = y_te\n",
    "\n",
    "# Filter the data\n",
    "g1 = X_te[X_te['Gender'] == 1]\n",
    "g2 = X_te[X_te['Gender'] == 0]\n",
    "\n",
    "# Filter the ground truth\n",
    "g1_true = aux[aux['Gender'] == 1].target\n",
    "g2_true = aux[aux['Gender'] == 0].target\n",
    "\n",
    "# Do predictions\n",
    "p1 = clf.predict(g1)\n",
    "p2 = clf.predict(g2)\n",
    "\n",
    "# Extract metrics for each group | here, taking the true positive rate\n",
    "res1 = calculate_cm(p1, g1_true)\n",
    "print(res1)\n",
    "res2 = calculate_cm(p2, g2_true)\n",
    "print(res2)\n",
    "\n",
    "res1 - res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 30]\n",
      " [ 0 55]]\n",
      "0.7272727272727273\n",
      "[[ 77   0]\n",
      " [ 62 196]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/\n",
    "# TPR = TP / (TP + FP)\n",
    "\n",
    "print(confusion_matrix(p1, g1_true))\n",
    "tpr_1 = confusion_matrix(p1, g1_true)[0][0] / (confusion_matrix(p1, g1_true)[0][0] + confusion_matrix(p1, g1_true)[0][1])\n",
    "print(tpr_1)\n",
    "\n",
    "print(confusion_matrix(p2, g2_true))\n",
    "tpr_2 = confusion_matrix(p2, g2_true)[0][0] / (confusion_matrix(p2, g2_true)[0][0] + confusion_matrix(p2, g2_true)[0][1])\n",
    "print(tpr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calculator(model, data: pd.DataFrame, truth: pd.DataFrame, col: str, group1, group2):\n",
    "    #reference group is group2!!\n",
    "    \n",
    "    aux = data.copy()\n",
    "    aux[\"target\"] = truth\n",
    "\n",
    "    # Filter the data\n",
    "    g1 = data[data[col] == group1]\n",
    "    g2 = data[data[col] == group2]\n",
    "\n",
    "    # Filter the ground truth\n",
    "    g1_true = aux[aux[col] == group1].target\n",
    "    g2_true = aux[aux[col] == group2].target\n",
    "\n",
    "    # Do predictions\n",
    "    p1 = model.predict(g1)\n",
    "    p2 = model.predict(g2)\n",
    "\n",
    "    # Extract metrics for each group | here, taking the true positive rate\n",
    "    res1 = calculate_cm(p1, g1_true)\n",
    "    print(res1)\n",
    "    res2 = calculate_cm(p2, g2_true)\n",
    "    print(res2)\n",
    "    \n",
    "    return res1 - res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5539568345323741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4460431654676259"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calculator(model=clf, data=X_te, truth=y_te, col='Gender', group1=1, group2=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6713286713286714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32867132867132864"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_calculator(model=clf, data=X_tr, truth=y_tr, col='Gender', group1=1, group2=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair_ml",
   "language": "python",
   "name": "fair_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
